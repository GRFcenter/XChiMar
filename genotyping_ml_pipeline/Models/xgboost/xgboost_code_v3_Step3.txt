##############################################################################################
## 0. Bulid xgboost best model using 5-fold nested cross validation.      ##  2025.08.21 ##
##############################################################################################
 
# Training data loading 

transformed_data <- read.table(
  "/Node4/Research/Project1/PGI-Marmoset-2022-12/Workspace/jhcha/machine_learning_marmoset/Journal_analysis/workspace/I4938_data/final/final_input_data.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE)



##################################################################
# 1. Building an xgboost model using 5-fold Nested cross validation method training
##################################################################

# Library loading 
library(caret)
library(xgboost)

set.seed(123)

# Step 1: Data (Training 80%, Test 20% - Maintain class ratio)
train_index <- createDataPartition(transformed_data$Y, p = 0.8, list = FALSE) 
train_data <- transformed_data[train_index, ]
test_data <- transformed_data[-train_index, ]

# Step 2: Outer 5-Fold CV   
outer_folds <- createFolds(train_data$Y, k = 5, returnTrain = TRUE) 

# Saving Result by list
nested_results <- list()

# Outer Loop (5-Fold)
for (i in 1:length(outer_folds)) {
  
  cat("\n===== Outer Fold", i, "=====\n")
  
  # Outer Fold: Train/Validation Set divide
  train_index_inner <- outer_folds[[i]]
  inner_train_data <- train_data[train_index_inner, ]
  validation_data <- train_data[-train_index_inner, ]
  
  # X, Y divide (using "abratio")
  x_inner_train <- as.matrix(inner_train_data[, "abratio", drop = FALSE])
  y_inner_train <- factor(inner_train_data$Y)  
  x_validation <- as.matrix(validation_data[, "abratio", drop = FALSE])
  y_validation <- factor(validation_data$Y)  

  # Step 3: Inner 5-Fold CV for Hyperparameter Tuning (Using "caret")
  train_control <- trainControl(
    method = "cv", 
    number = 5,
    verboseIter = FALSE,
    savePredictions = "final",
    classProbs = TRUE  # Using classProbs for probability-based predictions
  )

  # XGBoost Setting model parameters
  xgb_grid <- expand.grid(
    nrounds = 100,         
    eta = 0.1,             
    max_depth = 6,         
    gamma = 0,             
    colsample_bytree = 0.8, 
    min_child_weight = 1,  
    subsample = 0.8        
  )

  # Finding optimal hyperparameters via inner 5-fold CV (using "caret")
  xgb_tuned <- train(
    x_inner_train, y_inner_train,
    method = "xgbTree",
    trControl = train_control,
    tuneGrid = xgb_grid,
    metric = "Accuracy"
  )

  # Step 4: Predict the predicted value based on probability
  pred_prob <- predict(xgb_tuned, x_validation, type = "prob")

  # Convert to the class with the highest probability
  predictions <- colnames(pred_prob)[max.col(pred_prob, ties.method = "first")]

  # Factor transform to fit the actual y for comparison
  predictions <- factor(predictions, levels = levels(y_validation))

  # Accuracy calculation (excluding NA values)
  accuracy <- mean(predictions == y_validation, na.rm = TRUE)  

  cat("Validation Accuracy (Fold", i, "):", accuracy, "\n")

  # Save Results
  nested_results[[i]] <- list(
    best_model = xgb_tuned,  
    accuracy = accuracy
  )
}

# Step 5: Test Set Evaluation with the Optimal Model
best_outer_fold <- which.max(sapply(nested_results, function(x) x$accuracy))
final_model <- nested_results[[best_outer_fold]]$best_model

# Test Data conversion
test_data$Y <- factor(test_data$Y)  
y_test <- test_data$Y  

# Perform predictions on **Test Set (20%)** using the optimal model
test_pred_prob <- predict(final_model, as.matrix(test_data[, "abratio", drop = FALSE]), type = "prob")

# Convert to the class with the highest probability
test_predictions <- colnames(test_pred_prob)[max.col(test_pred_prob, ties.method = "first")]

# Factor transform to fit the actual y for comparison
test_predictions <- factor(test_predictions, levels = levels(y_test))

# Step 6. Calculate final test accuracy
test_accuracy <- mean(test_predictions == y_test, na.rm = TRUE)

cat("\n===== Final Test Set Accuracy:", test_accuracy, "=====\n")
# ===== Final Test Set Accuracy: 0.9704793 


#####################################################
# 3. Calculating additional performance metrics for Test Set(20%) 
#####################################################

# Confusion Matrix 
test_conf_matrix <- table(Predicted = test_predictions, Actual = y_test)
cat("\n=== Confusion Matrix (Test Data) ===\n")
print(test_conf_matrix)
#             Actual
# Predicted    HET HOM_REF HOM_ALT
#  HET     488627   12760    2997
#  HOM_REF  14021  239437     275
#  HOM_ALT   1956      99  327470


# Accuracy  
test_accuracy <- sum(diag(test_conf_matrix)) / sum(test_conf_matrix)
cat("\nTest Data Accuracy:", test_accuracy, "\n")
# Test Data Accuracy: 0.9704793 


# Balanced Accuracy  
test_balanced_accuracy <- mean(diag(prop.table(test_conf_matrix, 1)))
cat("Balanced Accuracy:", test_balanced_accuracy, "\n")
# Balanced Accuracy:  0.968727 


# Precision, Recall, F1-score  
test_precision <- diag(test_conf_matrix) / rowSums(test_conf_matrix)
test_recall <- diag(test_conf_matrix) / colSums(test_conf_matrix)
test_f1_score <- 2 * (test_precision * test_recall) / (test_precision + test_recall)

cat("\nPrecision (per class):", test_precision, "\n")
# Precision (per class): 0.9687599 0.9436573 0.9937638

cat("Recall (per class):", test_recall, "\n")
# Recall (per class): 0.9683375 0.9490321 0.9901071 

cat("F1-score (per class):", test_f1_score, "\n")
# F1-score (per class):  0.9685487 0.9463371 0.9919321  

# Error Rate  
test_error_rate <- 1 - test_accuracy
cat("Error Rate:", test_error_rate, "\n")
# Error Rate: 0.03360881 



# Multiclass AUC  
library(pROC)
test_roc <- multiclass.roc(response = y_test, predictor = as.matrix(test_pred_prob))
cat("Multiclass AUC:", test_roc$auc, "\n")
# Multiclass AUC: 0.994009 

# Area Under Precision-Recall Curve  
library(PRROC)
test_auprc <- sapply(1:ncol(test_pred_prob), function(i) {
  PR <- pr.curve(
    scores.class0 = test_pred_prob[, i], 
    weights.class0 = (y_test == levels(y_test)[i]), 
    curve = TRUE
  )
  PR$auc.integral
})
cat("AUPRC (per class):", test_auprc, "\n")
# AUPRC (per class) : 0.9903256 0.9646673 0.9946958 

saveRDS(final_model, file = "/BiO/Access/home/jhcha/xgboost_final_model.rds")  
 
# saveRDS(final_model, file = "/Node4/Research/Project1/PGI-Marmoset-2022-12/Workspace/jhcha/machine_learning_marmoset/Journal_analysis/code/xgboost_final_model.rds")

#############################################################################
# 4. Evaluate on external data with Test data (1722300M)
#############################################################################
 
execution_time <- system.time({

 # Data loading
file_path <- "/Node4/Research/Project1/PGI-Marmoset-2022-12/Workspace/jhcha/machine_learning_marmoset/1722300M_gvcf_parsing_output/merged_chr_final_dat/combined_fin.dat.txt"

  test_data_300M <- as.data.frame(fread(file_path))
  colnames(test_data_300M) <- c("CHROM", "POS", "abratio", "Y")

  test_data_300M$id <- paste(test_data_300M$CHROM, test_data_300M$POS, sep = "_")
  test_data_300M <- test_data_300M[, c("id", "abratio", "Y")]
  test_data_300M$Y <- as.factor(test_data_300M$Y)

# 예측 전에 반드시 레이블 변환
test_data_300M$Y <- factor(test_data_300M$Y,
                           levels = c("alt_ref", "ref_ref", "alt_alt"),
                           labels = c("HET", "HOM_REF", "HOM_ALT"))

  test_data_300M[which(test_data_300M$abratio <= 0.2),"Y"] <- "HOM_ALT"
  test_data_300M[which(test_data_300M$abratio > 0.2 & test_data_300M$abratio < 0.8), "Y"] <- "HET"
  test_data_300M[which(test_data_300M$abratio >= 0.8),"Y"] <- "HOM_REF"

  # Preparing for prediction
  x_test <- as.matrix(test_data_300M[, "abratio", drop = FALSE])
  y_test <- test_data_300M$Y

  # Prediction
  test_predictions <- predict(final_model, x_test)
  test_probabilities <- predict(final_model, x_test, type = "prob")

   
  test_conf_matrix <- table(Predicted = test_predictions, Actual = test_data_300M$Y)
  cat("\n=== Confusion Matrix (Test Data) ===\n")
  print(test_conf_matrix)
	# Actual
	# Predicted      HET  HOM_REF  HOM_ALT
	#  HET       324818    34718     5316
	#  HOM_REF        0 10520054        0
	#  HOM_ALT        0        0    68173

  test_accuracy <- sum(diag(test_conf_matrix)) / sum(test_conf_matrix)
  cat("\nTest Data Accuracy:", test_accuracy, "\n")
  # Test Data Accuracy: 0.996345 

  test_balanced_accuracy <- mean(diag(prop.table(test_conf_matrix, 1)))
  cat("Balanced Accuracy:", test_balanced_accuracy, "\n")
  # 0.9634244 

  test_precision <- diag(test_conf_matrix) / rowSums(test_conf_matrix)
  test_recall <- diag(test_conf_matrix) / colSums(test_conf_matrix)
  test_f1_score <- 2 * (test_precision * test_recall) / (test_precision + test_recall)

  cat("\nPrecision (per class):", test_precision, "\n")
	# 0.8902733 1 1
  cat("Recall (per class):", test_recall, "\n")
	# 1 0.9967107 0.9276626
  cat("F1-score (per class):", test_f1_score, "\n")
	# 0.9419519 0.9983526 0.9624741 

  test_error_rate <- 1 - test_accuracy
  cat("Error Rate:", test_error_rate, "\n")
	# 0.003655045 


  # AUC
  library(pROC)
  test_roc <- multiclass.roc(response = test_data_300M$Y, predictor = as.matrix(test_probabilities))
  cat("Multiclass AUC:", test_roc$auc, "\n")
	# 0.9993652 

  # AUPRC
  library(PRROC)
  test_auprc <- sapply(1:ncol(test_probabilities), function(i) {
    PR <- pr.curve(
      scores.class0 = test_probabilities[, i],
      weights.class0 = (test_data_300M$Y == levels(test_data_300M$Y)[i]),
      curve = TRUE
    )
    PR$auc.integral
  })
  cat("AUPRC (per class):", test_auprc, "\n")

}) 
#  
execution_time
#   user  system elapsed 
# 385.851  13.322 110.819 

=== Confusion Matrix (Test Data) ===
         Actual
Predicted      HET  HOM_REF  HOM_ALT
  HET       324818    34718     5316
  HOM_REF        0 10520054        0
  HOM_ALT        0        0    68173

Test Data Accuracy: 0.996345
Balanced Accuracy: 0.9634244

Precision (per class): 0.8902733 1 1
Recall (per class): 1 0.9967107 0.9276626
F1-score (per class): 0.9419519 0.9983526 0.9624741
Error Rate: 0.003655045
Multiclass AUC: 0.9993652
AUPRC (per class): 0.9985395 0.9999994 0.9999654

 
